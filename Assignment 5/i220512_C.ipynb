{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "74a7eaf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import pydub \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import librosa as lib\n",
    "from scipy.io import wavfile as wav\n",
    "from scipy.signal import stft\n",
    "import IPython\n",
    "import soundfile as sf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ee70fd",
   "metadata": {},
   "source": [
    "# Question: 1\n",
    "\n",
    "In this question, you are tasked with enhancing the resolution of a video. The goal is to improve the quality of individual frames. You are expected to use basic algorithms for achieving this goal. \n",
    "\n",
    "### Task 1: Frame Extraction\n",
    "\n",
    "Extract frames from the video using OpenCV.\n",
    "\n",
    "### Task 2: Resolution Enhancement\n",
    "\n",
    "Apply the following enhancement algorithms to scale the extracted frames by a factor of 2:\n",
    "\n",
    "1) Nearest-neighbor Interpolation <br>\n",
    "2) Bilinear Interpolation <br>\n",
    "3) Bicubic Interpolation <br>\n",
    "\n",
    "Explore these approaches by your self. These are just builtin parameters in resize function.\n",
    "https://theailearner.com/2018/11/15/image-interpolation-using-opencv-python/\n",
    "\n",
    "### Task 3: Video Reconstruction\n",
    "\n",
    "After enhancing the frames, reconstruct the video by merging the enhanced frames while ensuring that the frame rate of the reconstructed video matches that of the original video. Generate a separate video for each interpolation method.\n",
    "\n",
    "<b>Bonus</b>: Apply a self-selected algorithm to improve video quality. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2144ac75",
   "metadata": {},
   "outputs": [],
   "source": [
    "vid = cv2.VideoCapture('Q1.mp4')\n",
    "fps = int(vid.get(cv2.CAP_PROP_FPS))\n",
    "heightframe = int(vid.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "widthframe = int(vid.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "vid_type = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "enhance_file = cv2.VideoWriter('intercubic.mp4', vid_type, 30, (widthframe * 2, heightframe * 2))\n",
    "\n",
    "while True:\n",
    "    ret, frame = vid.read()\n",
    "    if ret:\n",
    "        outframe = cv2.resize(frame, None, fx=2, fy=2, interpolation=cv2.INTER_CUBIC)\n",
    "        enhance_file.write(outframe)\n",
    "        cv2.imshow('Frame', outframe)\n",
    "        if cv2.waitKey(30) & 0xFF == 27:\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "vid.release()\n",
    "enhance_file.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2aa2dcef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# orgframearr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "5a561284",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vid = cv2.VideoCapture('Q1.mp4')\n",
    "vid_type = cv2.VideoWriter_fourcc(*'XVID')\n",
    "enhance_file = cv2.VideoWriter('near_neigh.mp4',vid_type,30,(widthframe*2,heightframe*2))\n",
    "while True:\n",
    "    ret,frame = vid.read()\n",
    "    if ret == True:\n",
    "        outframe = cv2.resize(frame,None, fx = 2, fy = 2, interpolation = cv2.INTER_NEAREST)\n",
    "        enhance_file.write(outframe)\n",
    "    else:\n",
    "        break\n",
    "    if cv2.waitKey(30) & 0xFF == 27:\n",
    "        break\n",
    "vid.release()\n",
    "enhance_file.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "2e4eacd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vid = cv2.VideoCapture('Q1.mp4')\n",
    "vid_type = cv2.VideoWriter_fourcc(*'XVID')\n",
    "enhance_file = cv2.VideoWriter('linear.mp4',vid_type,29,(widthframe*2,heightframe*2))\n",
    "while True:\n",
    "    ret,frame = vid.read()\n",
    "    if ret == True:\n",
    "        b = cv2.resize(frame,None, fx = 2, fy = 2, interpolation = cv2.INTER_LINEAR)\n",
    "        enhance_file.write(b)\n",
    "    else:\n",
    "        break\n",
    "    if cv2.waitKey(30) & 0xFF == 27:\n",
    "        break\n",
    "vid.release()\n",
    "enhance_file.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "a9f5f2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### I dont know name of this exact algo but this looked like it produced better results than others\n",
    "\n",
    "vid = cv2.VideoCapture('Q1.mp4')\n",
    "vid_type = cv2.VideoWriter_fourcc(*'XVID')\n",
    "enhance_file = cv2.VideoWriter('AREA.mp4',vid_type,29,(widthframe*10,heightframe*10))\n",
    "while True:\n",
    "    ret,frame = vid.read()\n",
    "    if ret == True:\n",
    "        b = cv2.resize(frame,None, fx = 10, fy = 10, interpolation = cv2.INTER_LANCZOS4)  ## this one\n",
    "        enhance_file.write(b)\n",
    "    else:\n",
    "        break\n",
    "    if cv2.waitKey(30) & 0xFF == 27:\n",
    "        break\n",
    "vid.release()\n",
    "enhance_file.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eece6ff9",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83645d46",
   "metadata": {},
   "source": [
    "# Question: 2\n",
    "\n",
    "In this question, you are tasked with enhancing the audio quality of the video. Follow the given procedure to increase audio quality.\n",
    "\n",
    "### Step 1: Short-Time Fourier Transform (STFT)\n",
    "Compute the Short-Time Fourier Transform (STFT) of the audio signal. This operation transforms the audio into the frequency domain over short time intervals.\n",
    "\n",
    "### Step 2: Magnitude and Phase Extraction\n",
    "From the STFT, get the magnitude and phase using the np.abs() and np.angle() functions.\n",
    "\n",
    "### Step 3: Noise Profile Creation\n",
    "Load the noisy audio and calculate its STFT and magnitude from the STFT. Afterward, compute the average magnitude of the audio along axis=1 to generate a noise profile. This profile is essential for identifying and removing noise.\n",
    "\n",
    "### Step 4: Adjusting with a Hyperparameter\n",
    "Multiply the noise profile array by a hyperparameter represented as alpha. Experiment with various values of alpha to fine-tune the results. A good starting point is to set alpha to 2.\n",
    "\n",
    "### Step 5: Audio Denoising\n",
    "Subtract the mean noise array from the original audio (You may need to adjust the dimensions of the mean noise array to match with original audio). Ensure that any negative values in the resulting array are replaced with 0. This step effectively reduces noise in the audio.\n",
    "\n",
    "### Step 6: Incorporating Phase Information\n",
    "Multiply the modified audio by the complex exponential of the phase information obtained in step 3, which can be expressed as np.exp(1.0j * phase).\n",
    "\n",
    "### Step 7: Inverse Short-Time Fourier Transform (ISTFT)\n",
    "Reconstruct the audio by performing the Inverse Short Time Fourier Transform (ISTFT) on the modified audio signal using librosa. Save the resulting audio file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7940e6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndata , nsr = lib.load(\"Q2-Noise.wav\")\n",
    "odata, osr  = lib.load('Q2.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "fcdf475b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Nst  = lib.stft(ndata)\n",
    "Ost = lib.stft(odata)\n",
    "omag = np.abs(Ost)\n",
    "nmag = np.abs(Nst)                   ## absolute values of \n",
    "oang  =np.angle(Ost)             # original audio angle\n",
    "nang = np.angle(Nst)        # noise angle\n",
    "# print(nmag)\n",
    "# mean mag\n",
    "m_mag = np.mean(nmag,1)\n",
    "hyperparam = m_mag* 4\n",
    "# print(hyperparam.shape)\n",
    "# print(omag.shape)\n",
    "# print(oang.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "6c0381e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# omag = omag.reshape(587,1025)\n",
    "# omag.shape            ### this comes with some noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "de3e1c38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(587, 1025)\n",
      "(587, 1025)\n"
     ]
    }
   ],
   "source": [
    "trans = omag.T     # taking transpose so shapes are equal when subtracting\n",
    "# print(trans.shape)      # 587\n",
    "dnoise = []\n",
    "for i in range(len(trans)):\n",
    "    t = trans[i] - hyperparam      ## as hyper param is already in a simgle dimension we will iterate over trans to minus it from magnitude of orignial file\n",
    "    dnoise.append(t)\n",
    "dnoise = np.array(dnoise)\n",
    "print(dnoise.shape)\n",
    "dnoise = dnoise.T\n",
    "dnoise[dnoise<0] = 0\n",
    "# dnoise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "7c6ae99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# oang = oang.reshape(587,1025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "12a174d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phase = dnoise*np.exp(1.0j*oang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "2d00812e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = lib.istft(phase)\n",
    "sf.write('dnoisefile.wav',mod,osr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc88728",
   "metadata": {},
   "source": [
    "# Question: 3\n",
    "\n",
    "For this task, use whisper inference to generate text from the audio file. Use any translation library to translate the text into another language, and then utilize a TTS system to produce audio from the translated text. Supported Languages are :English, Urdu, Arabic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602468b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c77061",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
